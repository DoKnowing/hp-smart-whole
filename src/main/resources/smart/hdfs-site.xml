<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>

   <property>
           <name>dfs.name.dir</name>
           <value>file:///hdfsdata/hdfsnamespace/nndata</value>
		   <description>元数据存放的位置</description>
   </property>

   <property>
         <name>dfs.heartbeat.interval</name>
         <value>10</value>
		 <description>DN的心跳检测时间间隔，默认3秒</description>
   </property>
   
   <property>
          <name>dfs.data.dir</name>
          <value>file:///hdfsdata/hdfsdata/data</value>
   </property>
   
    <property>
            <name>dfs.nameservices</name>
            <value>smartcluster</value>
            <description>Comma-separated list of nameservices.</description>
   </property>

    <property>
              <name>dfs.ha.namenodes.smartcluster</name>
              <value>nn1</value>
              <description>
                           The ID of this namenode. If the namenode ID is not configured it
                           is determined automatically by matching the local node's address
                           with the configured address.
              </description>
   </property>
   <property>
              <name>ha.zookeeper.session-timeout.ms</name>
              <value>30000</value>
   </property>
   <property>
      <name>dfs.namenode.rpc-address.smartcluster.nn1</name>
      <value>smart-master:8020</value>
      <description>
         RPC address that handles all clients requests. In the case of HA/Federation where multiple namenodes exist,
         the name service id is added to the name e.g. dfs.namenode.rpc-address.ns1
         dfs.namenode.rpc-address.EXAMPLENAMESERVICE
         The value of this property will take the form of nn-host1:rpc-port.
       </description>
   </property>

   <property>
      <name>dfs.namenode.http-address.smartcluster.nn1</name>
      <value>smart-master:50070</value>
      <description>
          The address and the base port where the dfs namenode web ui will listen on.
      </description>
     </property>

    <property>
         <name>dfs.ha.automatic-failover.enabled</name>
         <value>true</value>
    </property>

    <property>
            <name>ha.zookeeper.quorum</name>
            <value>smart-master:2181,smart-slave1:2181,smart-slave2:2181</value>
    </property>


     <property>
              <name>dfs.permissions.enabled</name>
              <value>false</value>
              <description>
                       If "true", enable permission checking in HDFS.
                       If "false", permission checking is turned off,
                       but all other behavior is unchanged.
                       Switching from one parameter value to the other does not change the mode,
                       owner or group of files or directories.
              </description>
     </property>

    <property>
  	     <name>dfs.datanode.failed.volumes.tolerated</name>
  	     <value>0</value>
		 <description>dn允许磁盘损坏的个数,默认为0</description>
		 
    </property>

    <property>
            <name>dfs.datanode.max.transfer.threads</name>
            <value>5120</value>
            <description>
                  Specifies the maximum number of threads to use for transferring data
                  in and out of the DN.
				  数据传输最大线程，默认：16384
            </description>
     </property>

    <property>
            <name>dfs.blocksize</name>
            <value>134217728</value>
            <description>
                The default block size for new files, in bytes.
                You can use the following suffix (case insensitive):
                k(kilo), m(mega), g(giga), t(tera), p(peta), e(exa) to specify the size (such as 128k, 512m, 1g, etc.),
                Or provide complete size in bytes (such as 134217728 for 128 MB).
            </description>
    </property>

     <property>
           <name>dfs.datanode.du.reserved</name>
           <value>1073741824</value>
		    <description>
                表示在datanode对磁盘写时候，保留多少非dfs的磁盘空间，从而避免dfs将所在的磁盘写满,默认为0
            </description>
     </property>

    <property>
             <name>dfs.client.read.shortcircuit</name>
             <value>true</value>
             <description>
                        This configuration parameter turns on short-circuit local reads.
             </description>
    </property>
	<property>
            <name>dfs.datanode.data.dir.perm</name>
            <value>755</value>
            <description>Permissions for the directories on on the local filesystem where the DFS data node store its blocks. The permissions can either be octal or symbolic.
			</description>
   </property>

    <property>
                 <name>dfs.domain.socket.path</name>
                 <value>/var/lib/hadoop-hdfs/dn_socket</value>
	</property>

    <property>
            <name>dfs.block.local-path-access.user</name>
            <value>root</value>
            <description>
                      Comma separated list of the users allowd to open block files
                      on legacy short-circuit local read.
            </description>
    </property>

    <property>
           <name>dfs.replication</name>
           <value>1</value>
    </property>
    <property>
          <name>dfs.namenode.num.checkpoints.retained</name>
          <value>168</value>
          <description>The number of image checkpoint files that will be retained by the NameNode and Secondary NameNode in their storage directories. All edit logs necessary to recover an up-to-date namespace from the oldest retained checkpoint will also be retained. 
          </description>
    </property>
    <property>
          <name>dfs.namenode.num.extra.edits.retained</name>
          <value>10000000</value>
          <description>The number of extra transactions which should be retained beyond what is minimally necessary for a NN restart. This can be useful for audit purposes or for an HA setup where a remote Standby Node may have been offline for some time and need to have a longer backlog of retained edits in order to start again. Typically each edit is on the order of a few hundred bytes, so the default of 1 million edits should be on the order of hundreds of MBs or low GBs. NOTE: Fewer extra edits may be retained than value specified for this setting if doing so would mean that more segments would be retained than the number configured by dfs.namenode.max.extra.edits.segments.retained. 
          </description>
   </property>
   <property>
         <name>dfs.ha.log-roll.period</name>
         <value>300</value>
         <description>How often, in seconds, the StandbyNode should ask the active to roll edit logs. Since the StandbyNode only reads from finalized log segments, the StandbyNode will only be as up-to-date as how often the logs are rolled.Note that failover triggers a log roll so the StandbyNode will be up to date before it becomes active.
         </description>
  </property>
  <!-- 
  <property>
         <name>dfs.hosts.exclude</name>
         <value>/opt/software/hadoop/hdfs/etc/hadoop/excludes</value>
  </property>
  --> 
  <property>
         <name>dfs.namenode.fs-limits.max-component-length</name>
         <value>0</value>
         <description>Defines the maximum number of bytes in UTF-8 encoding in each component of a path.
            A value of 0 will disable the check.
         </description>
  </property>
  <!-- 
    <property>
         <name>dfs.datanode.address</name>
         <value>50010</value>
         <description>
             DN的服务监听端口，端口为0的话会随机监听端口，通过心跳通知NN，默认：50010
         </description>
  </property>
      <property>
         <name>dfs.datanode.http.address</name>
         <value>50075</value>
         <description>
             dn WebUI, 默认：50075
         </description>
  </property>
  -->
     <property>
             <name>dfs.client.failover.proxy.provider.smartcluster</name>
             <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
             <description> Configure the name of the Java class which will be used by the DFS Client to determine which NameNode is the current Active, and therefore which NameNode is currently serving client requests. The only implementation which currently ships with Hadoop is the ConfiguredFailoverProxyProvider, so use this unless you are using a custom one.
		</description>
	</property>
</configuration>
